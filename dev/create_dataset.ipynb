{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "\n",
    "* From raw json files, create the reviews df\n",
    "* From raw json files, create the items df\n",
    "* Standardize strings across the items df\n",
    "* Label encode the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JSON Files in action figures:   0%|          | 0/267 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JSON Files in action figures: 100%|██████████| 267/267 [00:00<00:00, 2566.72it/s]\n",
      "Loading JSON Files in adventure novel: 100%|██████████| 257/257 [00:00<00:00, 4430.08it/s]\n",
      "Loading JSON Files in air freshener: 100%|██████████| 222/222 [00:00<00:00, 3963.34it/s]\n",
      "Loading JSON Files in air fryer: 100%|██████████| 211/211 [00:00<00:00, 3767.01it/s]\n",
      "Loading JSON Files in air purifier: 100%|██████████| 198/198 [00:00<00:00, 3806.80it/s]\n",
      "Loading JSON Files in baby bottle: 100%|██████████| 219/219 [00:00<00:00, 3649.16it/s]\n",
      "Loading JSON Files in baby formula: 100%|██████████| 209/209 [00:00<00:00, 1990.03it/s]\n",
      "Loading JSON Files in baby wipes: 100%|██████████| 246/246 [00:00<00:00, 4168.51it/s]\n",
      "Loading JSON Files in bathroom: 100%|██████████| 48/48 [00:00<00:00, 3427.83it/s]\n",
      "Loading JSON Files in battery: 100%|██████████| 272/272 [00:00<00:00, 3941.14it/s]\n",
      "Loading JSON Files in bedding: 100%|██████████| 246/246 [00:00<00:00, 3236.08it/s]\n",
      "Loading JSON Files in bedframe: 100%|██████████| 246/246 [00:00<00:00, 1211.55it/s]\n",
      "Loading JSON Files in bedroom: 100%|██████████| 48/48 [00:00<00:00, 3427.83it/s]\n",
      "Loading JSON Files in belt: 100%|██████████| 268/268 [00:00<00:00, 3349.26it/s]\n",
      "Loading JSON Files in bookshelf: 100%|██████████| 273/273 [00:00<00:00, 3591.30it/s]\n",
      "Loading JSON Files in broom: 100%|██████████| 248/248 [00:00<00:00, 3814.51it/s]\n",
      "Loading JSON Files in building toys: 100%|██████████| 246/246 [00:00<00:00, 3842.87it/s]\n",
      "Loading JSON Files in cabinet: 100%|██████████| 246/246 [00:00<00:00, 3670.82it/s]\n",
      "Loading JSON Files in cables: 100%|██████████| 241/241 [00:00<00:00, 1442.79it/s]\n",
      "Loading JSON Files in camera: 100%|██████████| 204/204 [00:00<00:00, 3456.87it/s]\n",
      "Loading JSON Files in car accessories: 100%|██████████| 266/266 [00:00<00:00, 3693.60it/s]\n",
      "Loading JSON Files in car seat: 100%|██████████| 240/240 [00:00<00:00, 3870.12it/s]\n",
      "Loading JSON Files in carpet: 100%|██████████| 257/257 [00:00<00:00, 3095.69it/s]\n",
      "Loading JSON Files in cellphone: 100%|██████████| 224/224 [00:00<00:00, 3671.34it/s]\n",
      "Loading JSON Files in chair: 100%|██████████| 326/326 [00:00<00:00, 3542.72it/s]\n",
      "Loading JSON Files in chargers: 100%|██████████| 206/206 [00:00<00:00, 1089.70it/s]\n",
      "Loading JSON Files in coat: 100%|██████████| 283/283 [00:00<00:00, 3252.12it/s]\n",
      "Loading JSON Files in coffee maker: 100%|██████████| 231/231 [00:00<00:00, 3299.24it/s]\n",
      "Loading JSON Files in coffee_table: 100%|██████████| 46/46 [00:00<00:00, 3284.95it/s]\n",
      "Loading JSON Files in computer accessories: 100%|██████████| 230/230 [00:00<00:00, 3193.72it/s]\n",
      "Loading JSON Files in conditioner: 100%|██████████| 210/210 [00:00<00:00, 3619.87it/s]\n",
      "Loading JSON Files in couch: 100%|██████████| 45/45 [00:00<00:00, 3460.71it/s]\n",
      "Loading JSON Files in cpu cooler: 100%|██████████| 219/219 [00:00<00:00, 3649.16it/s]\n",
      "Loading JSON Files in crib: 100%|██████████| 247/247 [00:00<00:00, 3919.70it/s]\n",
      "Loading JSON Files in curtain: 100%|██████████| 282/282 [00:00<00:00, 3203.82it/s]\n",
      "Loading JSON Files in dashcam: 100%|██████████| 193/193 [00:00<00:00, 842.60it/s]\n",
      "Loading JSON Files in deodorant: 100%|██████████| 176/176 [00:00<00:00, 3825.17it/s]\n",
      "Loading JSON Files in desk: 100%|██████████| 274/274 [00:00<00:00, 3652.53it/s]\n",
      "Loading JSON Files in desk lamp: 100%|██████████| 262/262 [00:00<00:00, 3045.83it/s]\n",
      "Loading JSON Files in detergent: 100%|██████████| 253/253 [00:00<00:00, 3891.43it/s]\n",
      "Loading JSON Files in diaper: 100%|██████████| 259/259 [00:00<00:00, 4176.49it/s]\n",
      "Loading JSON Files in dining room: 100%|██████████| 48/48 [00:00<00:00, 3691.56it/s]\n",
      "Loading JSON Files in dishwasher: 100%|██████████| 249/249 [00:00<00:00, 3607.86it/s]\n",
      "Loading JSON Files in dress: 100%|██████████| 232/232 [00:00<00:00, 3361.55it/s]\n",
      "Loading JSON Files in dresser: 100%|██████████| 265/265 [00:00<00:00, 3486.07it/s]\n",
      "Loading JSON Files in dustpan: 100%|██████████| 268/268 [00:00<00:00, 3940.30it/s]\n",
      "Loading JSON Files in fabric conditioner: 100%|██████████| 245/245 [00:00<00:00, 4015.44it/s]\n",
      "Loading JSON Files in face mask: 100%|██████████| 216/216 [00:00<00:00, 3723.31it/s]\n",
      "Loading JSON Files in face wash: 100%|██████████| 250/250 [00:00<00:00, 816.81it/s]\n",
      "Loading JSON Files in facial toner: 100%|██████████| 254/254 [00:00<00:00, 3847.64it/s]\n",
      "Loading JSON Files in fantasy novel: 100%|██████████| 233/233 [00:00<00:00, 4016.36it/s]\n",
      "Loading JSON Files in feminine wash: 100%|██████████| 246/246 [00:00<00:00, 4187.33it/s]\n",
      "Loading JSON Files in first aid: 100%|██████████| 259/259 [00:00<00:00, 3983.74it/s]\n",
      "Loading JSON Files in folder: 100%|██████████| 234/234 [00:00<00:00, 3835.14it/s]\n",
      "Loading JSON Files in frying pan: 100%|██████████| 262/262 [00:00<00:00, 3638.03it/s]\n",
      "Loading JSON Files in furniture: 100%|██████████| 47/47 [00:00<00:00, 3614.19it/s]\n",
      "Loading JSON Files in garage: 100%|██████████| 49/49 [00:00<00:00, 2578.58it/s]\n",
      "Loading JSON Files in gps: 100%|██████████| 229/229 [00:00<00:00, 3880.45it/s]\n",
      "Loading JSON Files in gpu: 100%|██████████| 181/181 [00:00<00:00, 3933.89it/s]\n",
      "Loading JSON Files in hard drive: 100%|██████████| 356/356 [00:00<00:00, 3389.71it/s]\n",
      "Loading JSON Files in headphones: 100%|██████████| 203/203 [00:00<00:00, 3327.13it/s]\n",
      "Loading JSON Files in historical novel: 100%|██████████| 281/281 [00:00<00:00, 3696.53it/s]\n",
      "Loading JSON Files in home decor: 100%|██████████| 447/447 [00:00<00:00, 3546.82it/s]\n",
      "Loading JSON Files in home_office: 100%|██████████| 46/46 [00:00<00:00, 3285.11it/s]\n",
      "Loading JSON Files in intel amd processor: 100%|██████████| 144/144 [00:00<00:00, 462.92it/s]\n",
      "Loading JSON Files in iron: 100%|██████████| 199/199 [00:00<00:00, 4060.39it/s]\n",
      "Loading JSON Files in jewelry: 100%|██████████| 252/252 [00:00<00:00, 3705.06it/s]\n",
      "Loading JSON Files in keyboard: 100%|██████████| 228/228 [00:00<00:00, 3402.23it/s]\n",
      "Loading JSON Files in kitchen: 100%|██████████| 48/48 [00:00<00:00, 3691.29it/s]\n",
      "Loading JSON Files in kitchen knife: 100%|██████████| 268/268 [00:00<00:00, 3525.52it/s]\n",
      "Loading JSON Files in lamp: 100%|██████████| 233/233 [00:00<00:00, 2806.63it/s]\n",
      "Loading JSON Files in laptop: 100%|██████████| 207/207 [00:00<00:00, 3630.75it/s]\n",
      "Loading JSON Files in linen: 100%|██████████| 270/270 [00:00<00:00, 3332.61it/s]\n",
      "Loading JSON Files in living room: 100%|██████████| 48/48 [00:00<00:00, 2665.98it/s]\n",
      "Loading JSON Files in lotion: 100%|██████████| 239/239 [00:00<00:00, 3620.39it/s]\n",
      "Loading JSON Files in luggage: 100%|██████████| 247/247 [00:00<00:00, 3741.57it/s]\n",
      "Loading JSON Files in makeup: 100%|██████████| 261/261 [00:00<00:00, 3261.77it/s]\n",
      "Loading JSON Files in mattress: 100%|██████████| 125/125 [00:00<00:00, 3204.46it/s]\n",
      "Loading JSON Files in men bag: 100%|██████████| 260/260 [00:00<00:00, 3465.88it/s]\n",
      "Loading JSON Files in men jeans: 100%|██████████| 212/212 [00:00<00:00, 3211.39it/s]\n",
      "Loading JSON Files in men shirt: 100%|██████████| 197/197 [00:00<00:00, 3282.57it/s]\n",
      "Loading JSON Files in men shoes: 100%|██████████| 230/230 [00:00<00:00, 3193.75it/s]\n",
      "Loading JSON Files in men sweater: 100%|██████████| 252/252 [00:00<00:00, 3705.11it/s]\n",
      "Loading JSON Files in microphone: 100%|██████████| 267/267 [00:00<00:00, 635.57it/s]\n",
      "Loading JSON Files in microwave: 100%|██████████| 226/226 [00:00<00:00, 3644.33it/s]\n",
      "Loading JSON Files in mirror: 100%|██████████| 278/278 [00:00<00:00, 3914.63it/s]\n",
      "Loading JSON Files in moisturizer: 100%|██████████| 276/276 [00:00<00:00, 4057.94it/s]\n",
      "Loading JSON Files in monitor: 100%|██████████| 202/202 [00:00<00:00, 3543.03it/s]\n",
      "Loading JSON Files in mop: 100%|██████████| 248/248 [00:00<00:00, 3443.67it/s]\n",
      "Loading JSON Files in motherboard: 100%|██████████| 209/209 [00:00<00:00, 3602.64it/s]\n",
      "Loading JSON Files in mouse: 100%|██████████| 229/229 [00:00<00:00, 3468.87it/s]\n",
      "Loading JSON Files in mouthwash: 100%|██████████| 240/240 [00:00<00:00, 4137.07it/s]\n",
      "Loading JSON Files in mystery novel: 100%|██████████| 242/242 [00:00<00:00, 4652.82it/s]\n",
      "Loading JSON Files in napkin: 100%|██████████| 265/265 [00:00<00:00, 3839.72it/s]\n",
      "Loading JSON Files in night stand: 100%|██████████| 218/218 [00:00<00:00, 3694.09it/s]\n",
      "Loading JSON Files in nonfiction novel: 100%|██████████| 247/247 [00:00<00:00, 4115.72it/s]\n",
      "Loading JSON Files in notebook: 100%|██████████| 251/251 [00:00<00:00, 3920.99it/s]\n",
      "Loading JSON Files in nursery: 100%|██████████| 48/48 [00:00<00:00, 3691.42it/s]\n",
      "Loading JSON Files in office chair: 100%|██████████| 251/251 [00:00<00:00, 3534.41it/s]\n",
      "Loading JSON Files in oven: 100%|██████████| 206/206 [00:00<00:00, 3813.96it/s]\n",
      "Loading JSON Files in over the counter: 100%|██████████| 284/284 [00:00<00:00, 3785.81it/s]\n",
      "Loading JSON Files in pacifier: 100%|██████████| 252/252 [00:00<00:00, 3817.34it/s]\n",
      "Loading JSON Files in packing cubes: 100%|██████████| 197/197 [00:00<00:00, 3716.15it/s]\n",
      "Loading JSON Files in patio: 100%|██████████| 48/48 [00:00<00:00, 3427.71it/s]\n",
      "Loading JSON Files in pc chassis: 100%|██████████| 227/227 [00:00<00:00, 4202.78it/s]\n",
      "Loading JSON Files in pc fan: 100%|██████████| 226/226 [00:00<00:00, 4034.80it/s]\n",
      "Loading JSON Files in pc power supply: 100%|██████████| 215/215 [00:00<00:00, 4055.69it/s]\n",
      "Loading JSON Files in pc ram: 100%|██████████| 249/249 [00:00<00:00, 4696.95it/s]\n",
      "Loading JSON Files in phone case: 100%|██████████| 256/256 [00:00<00:00, 3709.32it/s]\n",
      "Loading JSON Files in pillow: 100%|██████████| 250/250 [00:00<00:00, 480.66it/s]\n",
      "Loading JSON Files in playroom: 100%|██████████| 48/48 [00:00<00:00, 2999.23it/s]\n",
      "Loading JSON Files in portable fan: 100%|██████████| 206/206 [00:00<00:00, 3376.24it/s]\n",
      "Loading JSON Files in printer: 100%|██████████| 216/216 [00:00<00:00, 3723.29it/s]\n",
      "Loading JSON Files in projector: 100%|██████████| 207/207 [00:00<00:00, 3568.15it/s]\n",
      "Loading JSON Files in ram vehicles: 100%|██████████| 193/193 [00:00<00:00, 4019.93it/s]\n",
      "Loading JSON Files in razor: 100%|██████████| 240/240 [00:00<00:00, 3933.56it/s]\n",
      "Loading JSON Files in ring doorbell: 100%|██████████| 251/251 [00:00<00:00, 4182.44it/s]\n",
      "Loading JSON Files in romance novel: 100%|██████████| 268/268 [00:00<00:00, 3999.11it/s]\n",
      "Loading JSON Files in school supplies: 100%|██████████| 256/256 [00:00<00:00, 3763.84it/s]\n",
      "Loading JSON Files in science fiction novel: 100%|██████████| 247/247 [00:00<00:00, 4048.29it/s]\n",
      "Loading JSON Files in screen protector: 100%|██████████| 219/219 [00:00<00:00, 3775.02it/s]\n",
      "Loading JSON Files in seat cushion: 100%|██████████| 249/249 [00:00<00:00, 3771.90it/s]\n",
      "Loading JSON Files in shampoo: 100%|██████████| 224/224 [00:00<00:00, 3393.13it/s]\n",
      "Loading JSON Files in shaving cream: 100%|██████████| 231/231 [00:00<00:00, 3665.84it/s]\n",
      "Loading JSON Files in shoe rack: 100%|██████████| 246/246 [00:00<00:00, 3616.83it/s]\n",
      "Loading JSON Files in smart watch: 100%|██████████| 185/185 [00:00<00:00, 3302.84it/s]\n",
      "Loading JSON Files in soap: 100%|██████████| 225/225 [00:00<00:00, 3213.52it/s]\n",
      "Loading JSON Files in solid state drive: 100%|██████████| 205/205 [00:00<00:00, 3917.75it/s]\n",
      "Loading JSON Files in speakers: 100%|██████████| 216/216 [00:00<00:00, 3540.17it/s]\n",
      "Loading JSON Files in stanley cup: 100%|██████████| 245/245 [00:00<00:00, 4015.49it/s]\n",
      "Loading JSON Files in stationery: 100%|██████████| 275/275 [00:00<00:00, 4434.53it/s]\n",
      "Loading JSON Files in steamer: 100%|██████████| 262/262 [00:00<00:00, 3796.20it/s]\n",
      "Loading JSON Files in stove: 100%|██████████| 189/189 [00:00<00:00, 3856.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading JSON from file ../dataset/extracts/amazon\\stove\\items\\amazon_B07V7JNTLB.json: file is empty or not a valid JSON.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JSON Files in stroller: 100%|██████████| 203/203 [00:00<00:00, 3382.60it/s]\n",
      "Loading JSON Files in surveillance camera: 100%|██████████| 234/234 [00:00<00:00, 3491.76it/s]\n",
      "Loading JSON Files in table: 100%|██████████| 285/285 [00:00<00:00, 3313.18it/s]\n",
      "Loading JSON Files in tablet: 100%|██████████| 186/186 [00:00<00:00, 3381.08it/s]\n",
      "Loading JSON Files in tampon: 100%|██████████| 248/248 [00:00<00:00, 4427.55it/s]\n",
      "Loading JSON Files in television: 100%|██████████| 208/208 [00:00<00:00, 3780.94it/s]\n",
      "Loading JSON Files in thriller novel: 100%|██████████| 265/265 [00:00<00:00, 3440.75it/s]\n",
      "Loading JSON Files in tires: 100%|██████████| 231/231 [00:00<00:00, 4357.45it/s]\n",
      "Loading JSON Files in tissue: 100%|██████████| 242/242 [00:00<00:00, 390.23it/s]\n",
      "Loading JSON Files in toddler toy: 100%|██████████| 258/258 [00:00<00:00, 3793.26it/s]\n",
      "Loading JSON Files in toilet: 100%|██████████| 265/265 [00:00<00:00, 3954.30it/s]\n",
      "Loading JSON Files in toothbrush: 100%|██████████| 237/237 [00:00<00:00, 3590.05it/s]\n",
      "Loading JSON Files in toy airplanes: 100%|██████████| 242/242 [00:00<00:00, 4564.99it/s]\n",
      "Loading JSON Files in toy cars: 100%|██████████| 250/250 [00:00<00:00, 3730.54it/s]\n",
      "Loading JSON Files in toy dolls: 100%|██████████| 277/277 [00:00<00:00, 4072.63it/s]\n",
      "Loading JSON Files in travel essentials: 100%|██████████| 226/226 [00:00<00:00, 3586.48it/s]\n",
      "Loading JSON Files in tripod: 100%|██████████| 212/212 [00:00<00:00, 3532.52it/s]\n",
      "Loading JSON Files in underwear: 100%|██████████| 235/235 [00:00<00:00, 3455.05it/s]\n",
      "Loading JSON Files in usb: 100%|██████████| 261/261 [00:00<00:00, 3727.74it/s]\n",
      "Loading JSON Files in utensils: 100%|██████████| 248/248 [00:00<00:00, 3756.72it/s]\n",
      "Loading JSON Files in vacuum: 100%|██████████| 196/196 [00:00<00:00, 3265.88it/s]\n",
      "Loading JSON Files in videogame console: 100%|██████████| 237/237 [00:00<00:00, 4308.08it/s]\n",
      "Loading JSON Files in vitamins: 100%|██████████| 249/249 [00:00<00:00, 3951.47it/s]\n",
      "Loading JSON Files in wall mount: 100%|██████████| 224/224 [00:00<00:00, 3999.06it/s]\n",
      "Loading JSON Files in washing machine: 100%|██████████| 202/202 [00:00<00:00, 4121.50it/s]\n",
      "Loading JSON Files in water flask: 100%|██████████| 304/304 [00:00<00:00, 1690.39it/s]\n",
      "Loading JSON Files in webcam: 100%|██████████| 173/173 [00:00<00:00, 3843.62it/s]\n",
      "Loading JSON Files in wifi router: 100%|██████████| 222/222 [00:00<00:00, 3638.56it/s]\n",
      "Loading JSON Files in women bag: 100%|██████████| 266/266 [00:00<00:00, 3022.05it/s]\n",
      "Loading JSON Files in women jeans: 100%|██████████| 251/251 [00:00<00:00, 2987.46it/s]\n",
      "Loading JSON Files in women shirt: 100%|██████████| 237/237 [00:00<00:00, 3337.30it/s]\n",
      "Loading JSON Files in women shoes: 100%|██████████| 244/244 [00:00<00:00, 3296.56it/s]\n",
      "Loading JSON Files in women sweater: 100%|██████████| 233/233 [00:00<00:00, 3376.05it/s]\n",
      "Loading JSON Files in workout clothes: 100%|██████████| 269/269 [00:00<00:00, 3279.76it/s]\n",
      "Loading JSON Files in young adult novel: 100%|██████████| 276/276 [00:00<00:00, 9515.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "save_to_dir = \"../dataset/utility\"\n",
    "if not os.path.exists(save_to_dir):\n",
    "    os.mkdir(save_to_dir)\n",
    "\n",
    "def clean_str(x):\n",
    "    x = unidecode(x)\n",
    "    x = '_'.join(x.replace('& ', '').split(' '))\n",
    "    return x.lower().strip().replace(\n",
    "        ',', '').replace('-', '').replace('?', '').replace(\n",
    "            '(', '').replace(')', '').replace('~', '').replace('*', '').replace('.', '')\n",
    "\n",
    "def items_and_reviews_to_dataframe(json_data):\n",
    "    iter = 0\n",
    "    products = []\n",
    "    reviews = []\n",
    "    asins = []\n",
    "    asin_product_mapping = []\n",
    "    for product_data in json_data:\n",
    "        product = {}\n",
    "        if ('body' not in product_data or 'reviews' not in product_data['body']\n",
    "            or 'productInformation' not in product_data['body']):\n",
    "            continue\n",
    "\n",
    "        reviews_data = product_data['body'].get('reviews', [])\n",
    "        product_name = product_data['body'].get('name', 'Unknown Product')\n",
    "        product_data = product_data['body']\n",
    "        asin = product_data['canonicalUrl'].split('/')[-1].lower()\n",
    "        if asin not in asins:\n",
    "            asin_product_mapping.append({\n",
    "                'ASIN': asin,\n",
    "                'name': product_name\n",
    "            })\n",
    "            asins.append(asin)\n",
    "        #print(f\"adding {iter}: {asin}\")\n",
    "        iter += 1\n",
    "\n",
    "        if not reviews_data or len(reviews_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        ignore = ['dimensions', 'country_of_origin', 'batteries_included',\n",
    "                  'weight', 'height', 'size', 'model', 'manufacturer',\n",
    "                  'specifications', 'voltage', 'volts', '12v', 'climate_pledge',\n",
    "                  'capacity', 'number_of_items', 'import', 'lxwxh', 'product'\n",
    "                  'included']\n",
    "\n",
    "        # form product data\n",
    "        product['ASIN'] = asin\n",
    "        product['customerReview'] = product_data.get('customerReview', 0)\n",
    "        product['brand'] = clean_str(product_data.get('brand', 'Unknown brand'))\n",
    "        if product.get('customerReview', 0) != 0:\n",
    "            product['customerReview'] = float(product['customerReview'].split(' ')[0])\n",
    "        breadcrumbs = product_data.get('breadCrumbs', [])\n",
    "        for bc in breadcrumbs:\n",
    "            name = clean_str(bc['name'])\n",
    "            flag = True\n",
    "            for ig in ignore:\n",
    "                if ig in name:\n",
    "                    flag = False\n",
    "            if flag and '_' in name:\n",
    "                name_list = name.split(\"_\")\n",
    "                for n in name_list:\n",
    "                    product[n] = 1.0\n",
    "            elif flag:\n",
    "                product[name] = 1.0\n",
    "        \n",
    "        products.append(product)\n",
    "\n",
    "        # form review data\n",
    "        review = {}\n",
    "        for r in reviews_data:\n",
    "            review['ASIN'] = asin\n",
    "            review['ProductName'] = clean_str(product_name)\n",
    "            review['reviewerID'] = r['reviewerName'] + '_' + r['reviewerLink'].split('/')[-1].split('.')[-1]\n",
    "            reviewRating = re.findall(r'(\\d+\\.\\d+)', r['reviewRating'])\n",
    "            reviewLocation = r['reviewDate'].split('on')[0].split(' in ')[-1].replace('the ', '')\n",
    "            reviewDate = re.findall(r'on (.+)$', r['reviewDate'])\n",
    "            reviewVotes = re.findall(r'(\\d+)', r['reviewVotes'])\n",
    "            if reviewRating:\n",
    "                review['reviewRating'] = float(reviewRating[0])\n",
    "            else:\n",
    "                review['reviewRating'] = np.nan\n",
    "            if reviewDate:\n",
    "                review['reviewDate'] = reviewDate[0]\n",
    "            else:\n",
    "                review['reviewDate'] = 'Unknown'\n",
    "            if reviewLocation:\n",
    "                review['reviewLocation'] = reviewLocation\n",
    "            else:\n",
    "                review['reviewLocation'] = 'Unknown'\n",
    "            if reviewVotes:\n",
    "                review['reviewVotes'] = reviewVotes[0]\n",
    "            else:\n",
    "                review['reviewVotes'] = 0\n",
    "            #print(f\"adding reviewer: {review['reviewerID']}\")\n",
    "            reviews.append(review)\n",
    "            review = {}\n",
    "    all_reviews_df = pd.DataFrame(reviews)\n",
    "    all_items_df = pd.DataFrame(products)\n",
    "    asins_df = pd.DataFrame(asin_product_mapping)\n",
    "    return all_reviews_df, all_items_df, asins_df\n",
    "\n",
    "def get_all_json_data():\n",
    "    base_dir = '../dataset/extracts/amazon'\n",
    "    all_json_data = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for dir in dirs:\n",
    "            items_path = os.path.join(root, dir, 'items')\n",
    "            if os.path.exists(items_path):\n",
    "                json_files = glob.glob(os.path.join(items_path, '*.json'))\n",
    "                \n",
    "                for json_file in tqdm(json_files, desc=f'Loading JSON Files in {dir}'):\n",
    "                    try:\n",
    "                        with open(json_file, \"r\") as f:\n",
    "                            all_json_data.append(json.load(f))\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error loading JSON from file {json_file}: file is empty or not a valid JSON.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Unexpected error loading JSON from file {json_file}: {e}\")\n",
    "    return all_json_data\n",
    "\n",
    "all_json_data = get_all_json_data()\n",
    "\n",
    "all_reviews_df, all_items_df, asins_df = items_and_reviews_to_dataframe(all_json_data)\n",
    "all_reviews_df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "all_reviews_df.to_csv(f\"{save_to_dir}/reviews.csv\", index=False)\n",
    "\n",
    "all_items_df.drop_duplicates(keep='first', inplace=True)\n",
    "all_items_df.to_csv(f\"{save_to_dir}/itemset_preprocessed.csv\", index=False)\n",
    "\n",
    "asins_df.to_csv(f\"{save_to_dir}/asin_product_mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Userbase\n",
    "\n",
    "Get TopN reviewers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_dir = \"../dataset/utility\"\n",
    "all_reviews_df = pd.read_csv(f\"{save_to_dir}/reviews.csv\")\n",
    "all_reviews_df = all_reviews_df.replace(np.nan, '', regex=True)\n",
    "user_ratings_df = all_reviews_df.drop([\n",
    "    \"reviewVotes\", \"reviewLocation\", \"reviewDate\",\n",
    "    \"ProductName\"], axis=1, inplace=False)\n",
    "groupby_df = user_ratings_df.groupby('reviewerID')\n",
    "freq = groupby_df['reviewerID'].value_counts()\n",
    "groupby_df_freq = pd.merge(user_ratings_df, freq, on='reviewerID', how='left')\n",
    "groupby_df_freq = groupby_df_freq.sort_values(['count'], ascending=False)\n",
    "\n",
    "mask = groupby_df_freq[\"count\"] >= 10\n",
    "groupby_df_freq = groupby_df_freq.loc[mask]\n",
    "\n",
    "topn_reviewers = pd.unique(groupby_df_freq[\"reviewerID\"])\n",
    "\n",
    "user_ratings_df.set_index(\"reviewerID\", inplace=True)\n",
    "user_ratings_grouped_df = user_ratings_df.loc[topn_reviewers].groupby('reviewerID')\n",
    "\n",
    "# identify and remove generic reviewerID\n",
    "generic_reviewerIDs = user_ratings_df.loc[topn_reviewers].groupby(\n",
    "    'reviewerID').count().sort_values('ASIN', ascending=False)[:8].index.tolist()\n",
    "topn_reviewers = [r for r in topn_reviewers if r not in generic_reviewerIDs]\n",
    "user_ratings_grouped_df = user_ratings_df.loc[topn_reviewers].groupby('reviewerID')\n",
    "\n",
    "rows = []\n",
    "iter = 0\n",
    "columns = pd.unique(all_reviews_df['ASIN']).tolist()\n",
    "columns.append(\"reviewerID\")\n",
    "\n",
    "for index, data in user_ratings_grouped_df:\n",
    "    row = {}\n",
    "    row['reviewerID'] = index\n",
    "    for ind, d in data.iterrows():\n",
    "        row[d['ASIN']] = d['reviewRating']\n",
    "    rows.append(row)\n",
    "    iter += 1\n",
    "fname = f\"{save_to_dir}/utility_topn.csv\"\n",
    "with open(fname, 'w', encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=columns)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utility = pd.read_csv(f\"{save_to_dir}/utility_topn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utility.set_index('reviewerID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check asin discrepancy\n",
    "asins_in_itemset = set(df_unique.index.tolist())\n",
    "asins_in_utility = set(df_utility.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33510"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asins_in_itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33510"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asins_in_utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
