{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "\n",
    "* From raw json files, create the reviews df\n",
    "* From raw json files, create the items df\n",
    "* Standardize strings across the items df\n",
    "* Label encode the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "save_to_dir = \"../dataset/utility\"\n",
    "if not os.path.exists(save_to_dir):\n",
    "    os.mkdir(save_to_dir)\n",
    "\n",
    "def clean_str(x):\n",
    "    forbidden_chars = [',', '-', '?', '(', ')',\n",
    "                       '~', '*', '.', '!']\n",
    "    x = unidecode(x)\n",
    "    x = '_'.join(x.replace('& ', '').split(' '))\n",
    "    x = x.lower().strip()\n",
    "    for c in forbidden_chars:\n",
    "        x = x.replace(c, '')\n",
    "    return x\n",
    "\n",
    "def items_and_reviews_to_dataframe(json_data):\n",
    "    products = []\n",
    "    reviews = []\n",
    "    asins = []\n",
    "    asin_product_mapping = []\n",
    "    for product_data in json_data:\n",
    "        product = {}\n",
    "        if ('body' not in product_data or 'reviews' not in product_data['body']\n",
    "            or 'productInformation' not in product_data['body']):\n",
    "            continue\n",
    "\n",
    "        reviews_data = product_data['body'].get('reviews', [])\n",
    "        product_name = product_data['body'].get('name', 'Unknown Product')\n",
    "        product_data = product_data['body']\n",
    "        asin = product_data['canonicalUrl'].split('/')[-1].lower()\n",
    "\n",
    "        if not reviews_data or len(reviews_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        ignore = ['dimensions', 'country_of_origin', 'batteries_included',\n",
    "                  'weight', 'height', 'size', 'model', 'manufacturer',\n",
    "                  'specifications', 'voltage', 'volts', '12v', 'climate_pledge',\n",
    "                  'capacity', 'number_of_items', 'import', 'lxwxh', 'product'\n",
    "                  'included']\n",
    "\n",
    "        product['ASIN'] = asin\n",
    "\n",
    "        if asin not in asins:\n",
    "            asin_product_mapping.append({\n",
    "                'ASIN': asin,\n",
    "                'name': product_name\n",
    "            })\n",
    "            asins.append(asin)\n",
    "        breadcrumbs = product_data.get('breadCrumbs', [])\n",
    "        for bc in breadcrumbs:\n",
    "            name = clean_str(bc['name'])\n",
    "            flag = True\n",
    "            for ig in ignore:\n",
    "                if ig in name:\n",
    "                    flag = False\n",
    "            if flag and '_' in name:\n",
    "                name_list = name.split(\"_\")\n",
    "                for n in name_list:\n",
    "                    product[n] = 1.0\n",
    "            elif flag:\n",
    "                product[name] = 1.0\n",
    "        \n",
    "        products.append(product)\n",
    "\n",
    "        review = {}\n",
    "        for r in reviews_data:\n",
    "            review['ASIN'] = asin\n",
    "            review['ProductName'] = clean_str(product_name)\n",
    "            review['reviewerID'] = r['reviewerName'] + '_' + r['reviewerLink'].split('/')[-1].split('.')[-1]\n",
    "            reviewRating = re.findall(r'(\\d+\\.\\d+)', r['reviewRating'])\n",
    "            reviewLocation = r['reviewDate'].split('on')[0].split(' in ')[-1].replace('the ', '')\n",
    "            reviewDate = re.findall(r'on (.+)$', r['reviewDate'])\n",
    "            reviewVotes = re.findall(r'(\\d+)', r['reviewVotes'])\n",
    "            if reviewRating:\n",
    "                review['reviewRating'] = float(reviewRating[0])\n",
    "            else:\n",
    "                review['reviewRating'] = np.nan\n",
    "            if reviewDate:\n",
    "                review['reviewDate'] = reviewDate[0]\n",
    "            else:\n",
    "                review['reviewDate'] = 'Unknown'\n",
    "            if reviewLocation:\n",
    "                review['reviewLocation'] = reviewLocation\n",
    "            else:\n",
    "                review['reviewLocation'] = 'Unknown'\n",
    "            if reviewVotes:\n",
    "                review['reviewVotes'] = reviewVotes[0]\n",
    "            else:\n",
    "                review['reviewVotes'] = 0\n",
    "            reviews.append(review)\n",
    "            review = {}\n",
    "    all_reviews_df = pd.DataFrame(reviews)\n",
    "    all_items_df = pd.DataFrame(products)\n",
    "    asins_df = pd.DataFrame(asin_product_mapping)\n",
    "    return all_reviews_df, all_items_df, asins_df\n",
    "\n",
    "def get_all_json_data():\n",
    "    base_dir = '../dataset/extracts/amazon'\n",
    "    all_json_data = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for dir in dirs:\n",
    "            items_path = os.path.join(root, dir, 'items')\n",
    "            if os.path.exists(items_path):\n",
    "                json_files = glob.glob(os.path.join(items_path, '*.json'))\n",
    "                \n",
    "                for json_file in tqdm(json_files, desc=f'Loading JSON Files in {dir}'):\n",
    "                    try:\n",
    "                        with open(json_file, \"r\") as f:\n",
    "                            all_json_data.append(json.load(f))\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error loading JSON from file {json_file}: file is empty or not a valid JSON.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Unexpected error loading JSON from file {json_file}: {e}\")\n",
    "    return all_json_data\n",
    "\n",
    "#all_json_data = get_all_json_data()\n",
    "\n",
    "all_reviews_df, all_items_df, asins_df = items_and_reviews_to_dataframe(all_json_data)\n",
    "all_reviews_df = all_reviews_df.replace(np.nan, '', regex=True)\n",
    "all_reviews_df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "all_reviews_df.to_csv(f\"{save_to_dir}/reviews.csv\")\n",
    "\n",
    "all_items_df.drop_duplicates(keep='first', inplace=True)\n",
    "all_items_df.fillna(0, inplace=True)\n",
    "\n",
    "asins_df.to_csv(f\"{save_to_dir}/asin_product_mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Itemset\n",
    "\n",
    "Merge like-ASINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items_df.reset_index(inplace=True)\n",
    "vc = all_items_df['ASIN'].value_counts()\n",
    "to_merge = vc.loc[lambda x: x > 1].index.tolist()\n",
    "\n",
    "all_items_df.set_index('ASIN', inplace=True)\n",
    "merge_dicts = []\n",
    "for asin in to_merge:\n",
    "    merged_row = all_items_df.loc[asin].sum()\n",
    "    merged_row = merged_row.drop('level_0')\n",
    "    d = merged_row.to_dict()\n",
    "    d['ASIN'] = asin\n",
    "    merge_dicts.append(d)\n",
    "    all_items_df.drop(asin, inplace=True)\n",
    "    \n",
    "merged_df = pd.DataFrame(merge_dicts)\n",
    "merged_df.set_index('ASIN', inplace=True)\n",
    "all_items_df = pd.concat([all_items_df, merged_df])\n",
    "all_items_df.to_csv(f\"{save_to_dir}/itemset_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Userbase\n",
    "\n",
    "Get TopN reviewers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_df = all_reviews_df.drop([\n",
    "    \"reviewVotes\", \"reviewLocation\", \"reviewDate\",\n",
    "    \"ProductName\"], axis=1, inplace=False)\n",
    "groupby_df = user_ratings_df.groupby('reviewerID')\n",
    "freq = groupby_df['reviewerID'].value_counts()\n",
    "groupby_df_freq = pd.merge(user_ratings_df, freq, on='reviewerID', how='left')\n",
    "groupby_df_freq = groupby_df_freq.sort_values(['count'], ascending=False)\n",
    "\n",
    "mask = groupby_df_freq[\"count\"] >= 10\n",
    "groupby_df_freq = groupby_df_freq.loc[mask]\n",
    "\n",
    "topn_reviewers = pd.unique(groupby_df_freq[\"reviewerID\"])\n",
    "\n",
    "user_ratings_df.set_index(\"reviewerID\", inplace=True)\n",
    "user_ratings_grouped_df = user_ratings_df.loc[topn_reviewers].groupby('reviewerID')\n",
    "\n",
    "generic_reviewerIDs = user_ratings_df.loc[topn_reviewers].groupby(\n",
    "    'reviewerID').count().sort_values('ASIN', ascending=False)[:8].index.tolist()\n",
    "topn_reviewers = [r for r in topn_reviewers if r not in generic_reviewerIDs]\n",
    "user_ratings_grouped_df = user_ratings_df.loc[topn_reviewers].groupby('reviewerID')\n",
    "\n",
    "rows = []\n",
    "iter = 0\n",
    "columns = all_items_df.index.tolist()\n",
    "columns.append(\"reviewerID\")\n",
    "\n",
    "for index, data in user_ratings_grouped_df:\n",
    "    row = {}\n",
    "    row['reviewerID'] = index\n",
    "    for ind, d in data.iterrows():\n",
    "        row[d['ASIN']] = d['reviewRating']\n",
    "    rows.append(row)\n",
    "    iter += 1\n",
    "\n",
    "df_utility = pd.DataFrame(rows, columns=columns)\n",
    "df_utility.to_csv(f\"{save_to_dir}/utility_topn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASIN\n",
       "b001f30182    1\n",
       "b08p59knm4    1\n",
       "b08p4mbk17    1\n",
       "b08mwqqhcd    1\n",
       "b08lg9g3jt    1\n",
       "             ..\n",
       "b0bnqymlyq    1\n",
       "b0bmv2c6lv    1\n",
       "b0bmpzd2xs    1\n",
       "b0bml7h9kq    1\n",
       "b0ctcy1wtr    1\n",
       "Name: count, Length: 33510, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_items_df.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b001f30182    1\n",
       "b08qtvhk6k    1\n",
       "b08p58jxj9    1\n",
       "b08p4mbk17    1\n",
       "b08mwqqhcd    1\n",
       "             ..\n",
       "b0bq2m742p    1\n",
       "b0bnqymlyq    1\n",
       "b0bmv2c6lv    1\n",
       "b0bmpzd2xs    1\n",
       "reviewerID    1\n",
       "Name: count, Length: 33511, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_utility.columns.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b001f30182</td>\n",
       "      <td>STAR WARS The Black Series Dark Trooper Toy 6-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b001gn794k</td>\n",
       "      <td>Avatar: The Last Airbender Prince Zuko 7\" Acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b00askv7fe</td>\n",
       "      <td>Hasbro Marvel Ultimate Spider-man Titan Hero S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b00hzsmwmy</td>\n",
       "      <td>Accoutrements Crazy Cat Lady Action Figure Mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b00ik8qpoy</td>\n",
       "      <td>Marvel Ultimate Spider-Man Titan Hero Series A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33505</th>\n",
       "      <td>b07zt8vlv4</td>\n",
       "      <td>Bestisun Womens Long Sleeve Workout Tops Yoga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33506</th>\n",
       "      <td>b0cqy9mrmr</td>\n",
       "      <td>Maxbee Flared Leggings with Pockets for Women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33507</th>\n",
       "      <td>b0cjr8rplq</td>\n",
       "      <td>TownCat Women’s Yoga Pants with Pockets, High ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33508</th>\n",
       "      <td>b0cr15gpvh</td>\n",
       "      <td>AUROLA Serpent Seamless Scrunch Workout Shorts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33509</th>\n",
       "      <td>b0cszbnwtw</td>\n",
       "      <td>3 Pack Biker Shorts Women - Seamless Ribbed Hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33510 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ASIN                                               name\n",
       "0      b001f30182  STAR WARS The Black Series Dark Trooper Toy 6-...\n",
       "1      b001gn794k  Avatar: The Last Airbender Prince Zuko 7\" Acti...\n",
       "2      b00askv7fe  Hasbro Marvel Ultimate Spider-man Titan Hero S...\n",
       "3      b00hzsmwmy  Accoutrements Crazy Cat Lady Action Figure Mul...\n",
       "4      b00ik8qpoy  Marvel Ultimate Spider-Man Titan Hero Series A...\n",
       "...           ...                                                ...\n",
       "33505  b07zt8vlv4  Bestisun Womens Long Sleeve Workout Tops Yoga ...\n",
       "33506  b0cqy9mrmr  Maxbee Flared Leggings with Pockets for Women ...\n",
       "33507  b0cjr8rplq  TownCat Women’s Yoga Pants with Pockets, High ...\n",
       "33508  b0cr15gpvh  AUROLA Serpent Seamless Scrunch Workout Shorts...\n",
       "33509  b0cszbnwtw  3 Pack Biker Shorts Women - Seamless Ribbed Hi...\n",
       "\n",
       "[33510 rows x 2 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
