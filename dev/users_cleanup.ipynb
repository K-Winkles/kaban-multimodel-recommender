{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c2bc1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "save_to_dir = \"../dataset/utility/users\"\n",
    "if not os.path.exists(save_to_dir):\n",
    "    os.mkdir(save_to_dir)\n",
    "\n",
    "def reviews_to_dataframe(json_data):\n",
    "    all_reviews_df = pd.DataFrame()\n",
    "    iter = 0\n",
    "    for product_data in json_data:\n",
    "        if 'body' not in product_data or 'reviews' not in product_data['body']:\n",
    "            continue\n",
    "        reviews_data = product_data['body'].get('reviews', [])\n",
    "        product_name = product_data['body'].get('name', 'Unknown Product')\n",
    "        asin = product_data['url'].split('/')[-1]\n",
    "\n",
    "        print(f\"adding review {iter}: {asin}\")\n",
    "        iter += 1\n",
    "        \n",
    "        if not reviews_data:\n",
    "            continue\n",
    "        \n",
    "        reviews_df = pd.DataFrame.from_records(reviews_data)\n",
    "\n",
    "        columns_to_include = [\n",
    "            \"reviewerName\",\n",
    "            'ASIN',\n",
    "            \"reviewerLink\", \n",
    "            \"reviewRating\", \n",
    "            \"reviewDate\", \n",
    "            \"reviewTitle\", \n",
    "            \"reviewText\", \n",
    "            \"reviewVotes\", \n",
    "            \"reviewVerifiedPurchase\"\n",
    "        ]\n",
    "        reviews_df['ASIN'] = asin\n",
    "        existing_columns = [col for col in columns_to_include if col in reviews_df.columns]\n",
    "        \n",
    "        if not existing_columns:\n",
    "            continue\n",
    "        \n",
    "        reviews_df = reviews_df[existing_columns]\n",
    "        \n",
    "        if 'reviewRating' in existing_columns:\n",
    "            reviews_df['reviewRating'] = reviews_df['reviewRating'].str.extract(r'(\\d+\\.\\d+)').astype(float)\n",
    "        if 'reviewDate' in existing_columns:\n",
    "            reviews_df[['Location', 'Date']] = reviews_df['reviewDate'].str.extract(r'Reviewed in the ([\\w\\s]+) on (.+)$')\n",
    "        if 'reviewVotes' in existing_columns:\n",
    "            reviews_df['reviewVotes'] = reviews_df['reviewVotes'].str.extract(r'(\\d+)').fillna(0).astype(int)\n",
    "        if 'reviewerLink' in existing_columns:\n",
    "            reviews_df['reviewerID'] = reviews_df['reviewerLink'].str.extract(r'.*amzn1.account.([^/]+)')\n",
    "        \n",
    "        for col in ['reviewDate', 'reviewerLink']:\n",
    "            if col in reviews_df.columns:\n",
    "                reviews_df.drop(columns=[col], inplace=True)\n",
    "        \n",
    "        reviews_df['ProductName'] = product_name\n",
    "        \n",
    "        \n",
    "        all_reviews_df = pd.concat([all_reviews_df, reviews_df], ignore_index=True)\n",
    "    \n",
    "    return all_reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45e3175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JSON Files in microwave: 100%|██████████| 226/226 [00:00<00:00, 4104.62it/s]\n",
      "Loading JSON Files in facial toner: 100%|██████████| 254/254 [00:00<00:00, 4327.68it/s]\n",
      "Loading JSON Files in lamp: 100%|██████████| 233/233 [00:00<00:00, 4180.26it/s]\n",
      "Loading JSON Files in luggage: 100%|██████████| 247/247 [00:00<00:00, 3921.08it/s]\n",
      "Loading JSON Files in bedroom: 100%|██████████| 48/48 [00:00<00:00, 5025.12it/s]\n",
      "Loading JSON Files in feminine wash: 100%|██████████| 246/246 [00:00<00:00, 4690.89it/s]\n",
      "Loading JSON Files in pc power supply: 100%|██████████| 215/215 [00:00<00:00, 4706.85it/s]\n",
      "Loading JSON Files in razor: 100%|██████████| 240/240 [00:00<00:00, 4454.17it/s]\n",
      "Loading JSON Files in tablet: 100%|██████████| 186/186 [00:00<00:00, 5034.79it/s]\n",
      "Loading JSON Files in fantasy novel: 100%|██████████| 233/233 [00:00<00:00, 4952.48it/s]\n",
      "Loading JSON Files in air fryer: 100%|██████████| 211/211 [00:00<00:00, 4747.33it/s]\n",
      "Loading JSON Files in coffee maker: 100%|██████████| 231/231 [00:00<00:00, 4682.93it/s]\n",
      "Loading JSON Files in wall mount: 100%|██████████| 224/224 [00:00<00:00, 4378.86it/s]\n",
      "Loading JSON Files in kitchen knife: 100%|██████████| 268/268 [00:00<00:00, 4904.29it/s]\n",
      "Loading JSON Files in women shoes: 100%|██████████| 244/244 [00:00<00:00, 4130.07it/s]\n",
      "Loading JSON Files in screen protector: 100%|██████████| 219/219 [00:00<00:00, 4518.63it/s]\n",
      "Loading JSON Files in motherboard: 100%|██████████| 209/209 [00:00<00:00, 5319.43it/s]\n",
      "Loading JSON Files in monitor: 100%|██████████| 202/202 [00:00<00:00, 4634.84it/s]\n",
      "Loading JSON Files in thriller novel: 100%|██████████| 265/265 [00:00<00:00, 5277.31it/s]\n",
      "Loading JSON Files in gpu: 100%|██████████| 181/181 [00:00<00:00, 4867.97it/s]\n",
      "Loading JSON Files in office chair: 100%|██████████| 251/251 [00:00<00:00, 4744.65it/s]\n",
      "Loading JSON Files in science fiction novel: 100%|██████████| 247/247 [00:00<00:00, 5487.77it/s]\n",
      "Loading JSON Files in chargers: 100%|██████████| 206/206 [00:00<00:00, 4345.45it/s]\n",
      "Loading JSON Files in projector: 100%|██████████| 207/207 [00:00<00:00, 4062.10it/s]\n",
      "Loading JSON Files in workout clothes: 100%|██████████| 269/269 [00:00<00:00, 4314.22it/s]\n",
      "Loading JSON Files in frying pan: 100%|██████████| 262/262 [00:00<00:00, 4586.66it/s]\n",
      "Loading JSON Files in microphone: 100%|██████████| 267/267 [00:00<00:00, 4104.23it/s]\n",
      "Loading JSON Files in desk: 100%|██████████| 274/274 [00:00<00:00, 4975.06it/s]\n",
      "Loading JSON Files in stroller: 100%|██████████| 203/203 [00:00<00:00, 5292.97it/s]\n",
      "Loading JSON Files in television: 100%|██████████| 208/208 [00:00<00:00, 4827.79it/s]\n",
      "Loading JSON Files in first aid: 100%|██████████| 259/259 [00:00<00:00, 5570.72it/s]\n",
      "Loading JSON Files in speakers: 100%|██████████| 216/216 [00:00<00:00, 4537.24it/s]\n",
      "Loading JSON Files in toddler toy: 100%|██████████| 258/258 [00:00<00:00, 5034.05it/s]\n",
      "Loading JSON Files in women shirt: 100%|██████████| 237/237 [00:00<00:00, 4397.67it/s]\n",
      "Loading JSON Files in steamer: 100%|██████████| 262/262 [00:00<00:00, 4683.52it/s]\n",
      "Loading JSON Files in stationery: 100%|██████████| 275/275 [00:00<00:00, 5717.85it/s]\n",
      "Loading JSON Files in gps: 100%|██████████| 229/229 [00:00<00:00, 4727.69it/s]\n",
      "Loading JSON Files in shaving cream: 100%|██████████| 231/231 [00:00<00:00, 5268.45it/s]\n",
      "Loading JSON Files in tires: 100%|██████████| 231/231 [00:00<00:00, 5733.11it/s]\n",
      "Loading JSON Files in face wash: 100%|██████████| 250/250 [00:00<00:00, 5110.77it/s]\n",
      "Loading JSON Files in belt: 100%|██████████| 268/268 [00:00<00:00, 5065.65it/s]\n",
      "Loading JSON Files in couch: 100%|██████████| 45/45 [00:00<00:00, 4580.16it/s]\n",
      "Loading JSON Files in fabric conditioner: 100%|██████████| 245/245 [00:00<00:00, 5251.53it/s]\n",
      "Loading JSON Files in curtain: 100%|██████████| 282/282 [00:00<00:00, 3574.38it/s]\n",
      "Loading JSON Files in washing machine: 100%|██████████| 202/202 [00:00<00:00, 3662.82it/s]\n",
      "Loading JSON Files in shoe rack: 100%|██████████| 246/246 [00:00<00:00, 4067.93it/s]\n",
      "Loading JSON Files in vitamins: 100%|██████████| 249/249 [00:00<00:00, 4273.02it/s]\n",
      "Loading JSON Files in men shirt: 100%|██████████| 197/197 [00:00<00:00, 4303.93it/s]\n",
      "Loading JSON Files in bathroom: 100%|██████████| 48/48 [00:00<00:00, 4994.83it/s]\n",
      "Loading JSON Files in vacuum: 100%|██████████| 196/196 [00:00<00:00, 4367.77it/s]\n",
      "Loading JSON Files in dress: 100%|██████████| 232/232 [00:00<00:00, 4777.30it/s]\n",
      "Loading JSON Files in camera: 100%|██████████| 204/204 [00:00<00:00, 4575.92it/s]\n",
      "Loading JSON Files in solid state drive: 100%|██████████| 205/205 [00:00<00:00, 4851.23it/s]\n",
      "Loading JSON Files in pc fan: 100%|██████████| 226/226 [00:00<00:00, 5354.20it/s]\n",
      "Loading JSON Files in underwear: 100%|██████████| 235/235 [00:00<00:00, 4789.18it/s]\n",
      "Loading JSON Files in coffee_table: 100%|██████████| 46/46 [00:00<00:00, 6578.18it/s]\n",
      "Loading JSON Files in lotion: 100%|██████████| 239/239 [00:00<00:00, 4439.81it/s]\n",
      "Loading JSON Files in pacifier: 100%|██████████| 252/252 [00:00<00:00, 4952.74it/s]\n",
      "Loading JSON Files in tissue: 100%|██████████| 242/242 [00:00<00:00, 4988.07it/s]\n",
      "Loading JSON Files in cellphone: 100%|██████████| 224/224 [00:00<00:00, 4301.18it/s]\n",
      "Loading JSON Files in women sweater: 100%|██████████| 233/233 [00:00<00:00, 4368.70it/s]\n",
      "Loading JSON Files in printer: 100%|██████████| 216/216 [00:00<00:00, 4872.77it/s]\n",
      "Loading JSON Files in air freshener: 100%|██████████| 222/222 [00:00<00:00, 4409.08it/s]\n",
      "Loading JSON Files in home_office: 100%|██████████| 46/46 [00:00<00:00, 4845.13it/s]\n",
      "Loading JSON Files in tampon: 100%|██████████| 248/248 [00:00<00:00, 5940.26it/s]\n",
      "Loading JSON Files in cabinet: 100%|██████████| 246/246 [00:00<00:00, 4901.77it/s]\n",
      "Loading JSON Files in folder: 100%|██████████| 234/234 [00:00<00:00, 4908.15it/s]\n",
      "Loading JSON Files in computer accessories: 100%|██████████| 230/230 [00:00<00:00, 4968.56it/s]\n",
      "Loading JSON Files in phone case: 100%|██████████| 256/256 [00:00<00:00, 295.74it/s]\n",
      "Loading JSON Files in over the counter: 100%|██████████| 284/284 [00:00<00:00, 3805.43it/s]\n",
      "Loading JSON Files in young adult novel: 100%|██████████| 276/276 [00:00<00:00, 7291.73it/s]\n",
      "Loading JSON Files in oven: 100%|██████████| 206/206 [00:00<00:00, 2657.96it/s]\n",
      "Loading JSON Files in chair: 100%|██████████| 326/326 [00:00<00:00, 4489.92it/s]\n",
      "Loading JSON Files in bookshelf: 100%|██████████| 273/273 [00:00<00:00, 5040.23it/s]\n",
      "Loading JSON Files in napkin: 100%|██████████| 265/265 [00:00<00:00, 4947.17it/s]\n",
      "Loading JSON Files in coat: 100%|██████████| 283/283 [00:00<00:00, 4630.09it/s]\n",
      "Loading JSON Files in headphones: 100%|██████████| 203/203 [00:00<00:00, 3479.73it/s]\n",
      "Loading JSON Files in dishwasher: 100%|██████████| 249/249 [00:00<00:00, 5378.78it/s]\n",
      "Loading JSON Files in building toys: 100%|██████████| 246/246 [00:00<00:00, 4978.14it/s]\n",
      "Loading JSON Files in dresser: 100%|██████████| 265/265 [00:00<00:00, 5189.35it/s]\n",
      "Loading JSON Files in men shoes: 100%|██████████| 230/230 [00:00<00:00, 4022.39it/s]\n",
      "Loading JSON Files in face mask: 100%|██████████| 216/216 [00:00<00:00, 5328.07it/s]\n",
      "Loading JSON Files in adventure novel: 100%|██████████| 257/257 [00:00<00:00, 5917.88it/s]\n",
      "Loading JSON Files in smart watch: 100%|██████████| 185/185 [00:00<00:00, 3592.53it/s]\n",
      "Loading JSON Files in soap: 100%|██████████| 225/225 [00:00<00:00, 5158.31it/s]\n",
      "Loading JSON Files in carpet: 100%|██████████| 257/257 [00:00<00:00, 4569.38it/s]\n",
      "Loading JSON Files in romance novel: 100%|██████████| 268/268 [00:00<00:00, 5444.17it/s]\n",
      "Loading JSON Files in jewelry: 100%|██████████| 252/252 [00:00<00:00, 4262.30it/s]\n",
      "Loading JSON Files in pc ram: 100%|██████████| 249/249 [00:00<00:00, 5691.05it/s]\n",
      "Loading JSON Files in furniture: 100%|██████████| 47/47 [00:00<00:00, 6268.32it/s]\n",
      "Loading JSON Files in action figures: 100%|██████████| 267/267 [00:00<00:00, 2600.31it/s]\n",
      "Loading JSON Files in toy dolls: 100%|██████████| 277/277 [00:00<00:00, 4670.36it/s]\n",
      "Loading JSON Files in mouthwash: 100%|██████████| 240/240 [00:00<00:00, 5172.94it/s]\n",
      "Loading JSON Files in dashcam: 100%|██████████| 193/193 [00:00<00:00, 4754.53it/s]\n",
      "Loading JSON Files in mouse: 100%|██████████| 229/229 [00:00<00:00, 4798.14it/s]\n",
      "Loading JSON Files in deodorant: 100%|██████████| 176/176 [00:00<00:00, 3961.84it/s]\n",
      "Loading JSON Files in toilet: 100%|██████████| 265/265 [00:00<00:00, 5218.61it/s]\n",
      "Loading JSON Files in usb: 100%|██████████| 261/261 [00:00<00:00, 5002.57it/s]\n",
      "Loading JSON Files in surveillance camera: 100%|██████████| 234/234 [00:00<00:00, 4629.37it/s]\n",
      "Loading JSON Files in packing cubes: 100%|██████████| 197/197 [00:00<00:00, 5067.82it/s]\n",
      "Loading JSON Files in stove: 100%|██████████| 189/189 [00:00<00:00, 5097.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading JSON from file ../dataset/extracts/amazon/stove/items/amazon_B07V7JNTLB.json: file is empty or not a valid JSON.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JSON Files in pillow: 100%|██████████| 250/250 [00:00<00:00, 4758.64it/s]\n",
      "Loading JSON Files in nonfiction novel: 100%|██████████| 247/247 [00:00<00:00, 5503.08it/s]\n",
      "Loading JSON Files in playroom: 100%|██████████| 48/48 [00:00<00:00, 6654.54it/s]\n",
      "Loading JSON Files in utensils: 100%|██████████| 248/248 [00:00<00:00, 4696.70it/s]\n",
      "Loading JSON Files in car seat: 100%|██████████| 240/240 [00:00<00:00, 5256.35it/s]\n",
      "Loading JSON Files in water flask: 100%|██████████| 304/304 [00:00<00:00, 4970.56it/s]\n",
      "Loading JSON Files in historical novel: 100%|██████████| 281/281 [00:00<00:00, 5283.94it/s]\n",
      "Loading JSON Files in patio: 100%|██████████| 48/48 [00:00<00:00, 6596.33it/s]\n",
      "Loading JSON Files in cpu cooler: 100%|██████████| 219/219 [00:00<00:00, 4429.17it/s]\n",
      "Loading JSON Files in men sweater: 100%|██████████| 252/252 [00:00<00:00, 4981.34it/s]\n",
      "Loading JSON Files in table: 100%|██████████| 285/285 [00:00<00:00, 5120.55it/s]\n",
      "Loading JSON Files in women jeans: 100%|██████████| 251/251 [00:00<00:00, 4523.84it/s]\n",
      "Loading JSON Files in moisturizer: 100%|██████████| 276/276 [00:00<00:00, 5146.36it/s]\n",
      "Loading JSON Files in pc chassis: 100%|██████████| 227/227 [00:00<00:00, 5149.73it/s]\n",
      "Loading JSON Files in desk lamp: 100%|██████████| 262/262 [00:00<00:00, 4579.28it/s]\n",
      "Loading JSON Files in women bag: 100%|██████████| 266/266 [00:00<00:00, 4519.60it/s]\n",
      "Loading JSON Files in iron: 100%|██████████| 199/199 [00:00<00:00, 5396.92it/s]\n",
      "Loading JSON Files in diaper: 100%|██████████| 259/259 [00:00<00:00, 5820.49it/s]\n",
      "Loading JSON Files in makeup: 100%|██████████| 261/261 [00:00<00:00, 4498.51it/s]\n",
      "Loading JSON Files in bedding: 100%|██████████| 246/246 [00:00<00:00, 4640.36it/s]\n",
      "Loading JSON Files in broom: 100%|██████████| 248/248 [00:00<00:00, 4563.09it/s]\n",
      "Loading JSON Files in mystery novel: 100%|██████████| 242/242 [00:00<00:00, 5992.64it/s]\n",
      "Loading JSON Files in videogame console: 100%|██████████| 237/237 [00:00<00:00, 5960.18it/s]\n",
      "Loading JSON Files in night stand: 100%|██████████| 218/218 [00:00<00:00, 4706.90it/s]\n",
      "Loading JSON Files in travel essentials: 100%|██████████| 226/226 [00:00<00:00, 4966.27it/s]\n",
      "Loading JSON Files in dining room: 100%|██████████| 48/48 [00:00<00:00, 4790.87it/s]\n",
      "Loading JSON Files in ring doorbell: 100%|██████████| 251/251 [00:00<00:00, 5268.88it/s]\n",
      "Loading JSON Files in nursery: 100%|██████████| 48/48 [00:00<00:00, 5825.76it/s]\n",
      "Loading JSON Files in detergent: 100%|██████████| 253/253 [00:00<00:00, 4437.82it/s]\n",
      "Loading JSON Files in baby formula: 100%|██████████| 209/209 [00:00<00:00, 5693.42it/s]\n",
      "Loading JSON Files in dustpan:  19%|█▉        | 51/268 [00:02<00:11, 19.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 13\u001b[0m         all_json_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading JSON from file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: file is empty or not a valid JSON.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_dir = '../dataset/extracts/amazon'\n",
    "all_json_data = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for dir in dirs:\n",
    "        items_path = os.path.join(root, dir, 'items')\n",
    "        if os.path.exists(items_path):\n",
    "            json_files = glob.glob(os.path.join(items_path, '*.json'))\n",
    "            \n",
    "            for json_file in tqdm(json_files, desc=f'Loading JSON Files in {dir}'):\n",
    "                try:\n",
    "                    with open(json_file, \"r\") as f:\n",
    "                        all_json_data.append(json.load(f))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error loading JSON from file {json_file}: file is empty or not a valid JSON.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error loading JSON from file {json_file}: {e}\")\n",
    "\n",
    "all_reviews_df = reviews_to_dataframe(all_json_data)\n",
    "all_reviews_df.head()\n",
    "all_reviews_df.to_csv(f\"{save_to_dir}/reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa38c7e",
   "metadata": {},
   "source": [
    "## Form User-Rating Matrix\n",
    "\n",
    "Two approaches:\n",
    "* Split userbase into 20K users per file\n",
    "* Get top N reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ad56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_dir = \"../dataset/utility/users\"\n",
    "\n",
    "all_reviews_df = pd.read_csv(f\"{save_to_dir}/reviews.csv\")\n",
    "columns = pd.unique(all_reviews_df['ASIN']).tolist()\n",
    "columns.append(\"reviewerID\")\n",
    "all_reviews_df = all_reviews_df.replace(np.nan, '', regex=True)\n",
    "all_reviews_df[\"reviewerID\"] =  all_reviews_df[\"reviewerName\"] + '_' + all_reviews_df[\"reviewerID\"]\n",
    "user_ratings_df = all_reviews_df.drop([\n",
    "    \"reviewTitle\", \"reviewText\", \"reviewVotes\",\n",
    "    \"reviewVerifiedPurchase\", \"Location\", \"Date\",\n",
    "    \"ProductName\"], axis=1, inplace=False)\n",
    "user_ratings_df.drop([\"reviewerName\"], axis=1, inplace=True)\n",
    "user_ratings_df = user_ratings_df.groupby([\"reviewerID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "rows = []\n",
    "iter = 0\n",
    "\n",
    "for index, data in user_ratings_df:\n",
    "    print(f\"iter: {iter} | {index[0]}\")\n",
    "    data = data.to_dict()\n",
    "    row = {}\n",
    "    row[\"reviewerID\"] = index[0]\n",
    "    for i in data[\"ASIN\"]:\n",
    "        asin = data[\"ASIN\"][i]\n",
    "        rating = data[\"reviewRating\"][i]\n",
    "        row[asin] = rating\n",
    "    rows.append(row)\n",
    "    iter += 1\n",
    "    if iter % 10000 == 0:\n",
    "        fname = f\"{save_to_dir}/utility_{iter}.csv\"\n",
    "        with open(fname, 'w') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(rows)\n",
    "        rows = []\n",
    "fname = f\"{save_to_dir}/utility_{iter}.csv\"\n",
    "with open(fname, 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=columns)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4771c71",
   "metadata": {},
   "source": [
    "# Get top N reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2fce18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_dir = \"../dataset/utility/users\"\n",
    "all_reviews_df = pd.read_csv(f\"{save_to_dir}/reviews.csv\")\n",
    "all_reviews_df = all_reviews_df.replace(np.nan, '', regex=True)\n",
    "all_reviews_df[\"reviewerID\"] =  all_reviews_df[\"reviewerName\"].astype(str) + '_' + all_reviews_df[\"reviewerID\"].astype(str)\n",
    "user_ratings_df = all_reviews_df.drop([\n",
    "    \"reviewTitle\", \"reviewText\", \"reviewVotes\",\n",
    "    \"reviewVerifiedPurchase\", \"Location\", \"Date\",\n",
    "    \"ProductName\"], axis=1, inplace=False)\n",
    "user_ratings_df.drop([\"reviewerName\"], axis=1, inplace=True)\n",
    "groupby_df = user_ratings_df.groupby('reviewerID')\n",
    "freq = groupby_df['reviewerID'].value_counts()\n",
    "groupby_df_freq = pd.merge(user_ratings_df, freq, on='reviewerID', how='left')\n",
    "groupby_df_freq = groupby_df_freq.sort_values(['count'], ascending=False)\n",
    "\n",
    "mask = groupby_df_freq[\"count\"] >= 10\n",
    "groupby_df_freq = groupby_df_freq.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd4cd31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>reviewRating</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74626</th>\n",
       "      <td>B09XM96H87</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazon Customer_</td>\n",
       "      <td>3554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295270</th>\n",
       "      <td>B08NWS6CH3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazon Customer_</td>\n",
       "      <td>3554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159270</th>\n",
       "      <td>B0CN3RHMF9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazon Customer_</td>\n",
       "      <td>3554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159236</th>\n",
       "      <td>B09FR31CPF</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazon Customer_</td>\n",
       "      <td>3554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159212</th>\n",
       "      <td>B0B1RLT5L2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazon Customer_</td>\n",
       "      <td>3554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274765</th>\n",
       "      <td>B084LHNR57</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SD_</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72061</th>\n",
       "      <td>B0C4GZN99V</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XennialLifeXennialLife_AGXDPEOXPMPIHIWPVXTBYFB...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90170</th>\n",
       "      <td>B092Q348ZC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cynthia_</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203282</th>\n",
       "      <td>B0748G2F3D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>live love laugh_AGEJVATBEAWO46BMRZTXDTIANJFQ</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276656</th>\n",
       "      <td>B00OVQO66S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GB_</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14286 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ASIN  reviewRating  \\\n",
       "74626   B09XM96H87           5.0   \n",
       "295270  B08NWS6CH3           5.0   \n",
       "159270  B0CN3RHMF9           5.0   \n",
       "159236  B09FR31CPF           5.0   \n",
       "159212  B0B1RLT5L2           5.0   \n",
       "...            ...           ...   \n",
       "274765  B084LHNR57           5.0   \n",
       "72061   B0C4GZN99V           5.0   \n",
       "90170   B092Q348ZC           4.0   \n",
       "203282  B0748G2F3D           5.0   \n",
       "276656  B00OVQO66S           5.0   \n",
       "\n",
       "                                               reviewerID  count  \n",
       "74626                                    Amazon Customer_   3554  \n",
       "295270                                   Amazon Customer_   3554  \n",
       "159270                                   Amazon Customer_   3554  \n",
       "159236                                   Amazon Customer_   3554  \n",
       "159212                                   Amazon Customer_   3554  \n",
       "...                                                   ...    ...  \n",
       "274765                                                SD_     10  \n",
       "72061   XennialLifeXennialLife_AGXDPEOXPMPIHIWPVXTBYFB...     10  \n",
       "90170                                            Cynthia_     10  \n",
       "203282       live love laugh_AGEJVATBEAWO46BMRZTXDTIANJFQ     10  \n",
       "276656                                                GB_     10  \n",
       "\n",
       "[14286 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_df_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd1e53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_reviewers = pd.unique(groupby_df_freq[\"reviewerID\"])\n",
    "user_ratings_df.set_index(\"reviewerID\", inplace=True)\n",
    "user_ratings_df.loc[topn_reviewers]\n",
    "user_ratings_grouped_df = user_ratings_df.loc[topn_reviewers].groupby('reviewerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34ae02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and remove generic reviewerID\n",
    "generic_reviewerIDs = user_ratings_df.loc[topn_reviewers].groupby('reviewerID').count().sort_values('ASIN', ascending=False)[:8].index.tolist()\n",
    "topn_reviewers = [r for r in topn_reviewers if r not in generic_reviewerIDs]\n",
    "user_ratings_grouped_df = user_ratings_df.loc[topn_reviewers].groupby('reviewerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4226f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 | ***Toy Collector***_AG5NFKDKQNEYV76GKH7BMXNTHKSQ\n",
      "iter: 1 | A._\n",
      "iter: 2 | AJ_\n",
      "iter: 3 | A_\n",
      "iter: 4 | Aaron_\n",
      "iter: 5 | Adam Nelson_AHIL2JHWADD6Z5U277LX5WLGG2VA\n",
      "iter: 6 | Adam_\n",
      "iter: 7 | Adrian_\n",
      "iter: 8 | Adriana_\n",
      "iter: 9 | Al_\n",
      "iter: 10 | Alan_\n",
      "iter: 11 | Alberto_\n",
      "iter: 12 | Ale_\n",
      "iter: 13 | Alejandra_\n",
      "iter: 14 | Alejandro_\n",
      "iter: 15 | Alessandro_\n",
      "iter: 16 | AlexAlex_\n",
      "iter: 17 | Alex_\n",
      "iter: 18 | Alexandra_\n",
      "iter: 19 | Alfredo_\n",
      "iter: 20 | Ali_\n",
      "iter: 21 | Alicia_\n",
      "iter: 22 | Amanda_\n",
      "iter: 23 | Amazon-Kunde_\n",
      "iter: 24 | Amazonlover_AG62UD7Q67DBARLYYTGSWHASW33Q\n",
      "iter: 25 | Amazonカスタマー_\n",
      "iter: 26 | Amber_\n",
      "iter: 27 | Amy_\n",
      "iter: 28 | Ana_\n",
      "iter: 29 | Andre_\n",
      "iter: 30 | Andrea_\n",
      "iter: 31 | Andrew_\n",
      "iter: 32 | Andy_\n",
      "iter: 33 | Angel_\n",
      "iter: 34 | Angela_\n",
      "iter: 35 | Angie_\n",
      "iter: 36 | Ann_\n",
      "iter: 37 | Anna_\n",
      "iter: 38 | Anne_\n",
      "iter: 39 | Annie_\n",
      "iter: 40 | Anon_\n",
      "iter: 41 | Anonymous _\n",
      "iter: 42 | Anonymous_\n",
      "iter: 43 | Antonio_\n",
      "iter: 44 | Armando_\n",
      "iter: 45 | Arturo_\n",
      "iter: 46 | AseAware_AEYZWWDY354SEDQR36DCXOHQGQDA\n",
      "iter: 47 | Ash_\n",
      "iter: 48 | Ashley_\n",
      "iter: 49 | Audrey_\n",
      "iter: 50 | BB_\n",
      "iter: 51 | BBumbolow_AEJJOHIAI3G4UULSDJT7LDGRX4VQ\n",
      "iter: 52 | B_\n",
      "iter: 53 | Barb_\n",
      "iter: 54 | Barbara_\n",
      "iter: 55 | Beatriz_\n",
      "iter: 56 | Ben_\n",
      "iter: 57 | Bill_\n",
      "iter: 58 | Bob_\n",
      "iter: 59 | Bonnie_\n",
      "iter: 60 | Brad_\n",
      "iter: 61 | Brandon_\n",
      "iter: 62 | Brenda_\n",
      "iter: 63 | Brian_\n",
      "iter: 64 | Brittany_AG4S554HFFBDNWNQ3VCVRKLRXR6A\n",
      "iter: 65 | Buyer_\n",
      "iter: 66 | CAPN_AFBET2H7MCXAPSEHMKDLC3UNYTFQ\n",
      "iter: 67 | CC_\n",
      "iter: 68 | CJ_\n",
      "iter: 69 | CS_\n",
      "iter: 70 | C_\n",
      "iter: 71 | Carla_\n",
      "iter: 72 | Carlos_\n",
      "iter: 73 | Carmen_\n",
      "iter: 74 | Caro_\n",
      "iter: 75 | Carol Fletcher_\n",
      "iter: 76 | Carol_\n",
      "iter: 77 | Caroline_\n",
      "iter: 78 | Carolyn_\n",
      "iter: 79 | Cat_\n",
      "iter: 80 | Cathy_\n",
      "iter: 81 | Cecilia_\n",
      "iter: 82 | Cesar_\n",
      "iter: 83 | Charles Scott_AFMSFDF4URKWUW4KYCOGURAQ2VJQ\n",
      "iter: 84 | Charles_\n",
      "iter: 85 | Cheryl_\n",
      "iter: 86 | Chicago Dan_AEEMRVC4FH66OMPCCHMWCQTMARTQ\n",
      "iter: 87 | Chris_\n",
      "iter: 88 | Christian_\n",
      "iter: 89 | Christine_\n",
      "iter: 90 | Cindy_\n",
      "iter: 91 | Claire_\n",
      "iter: 92 | Claudia_\n",
      "iter: 93 | Client Kindle_\n",
      "iter: 94 | Client d'AmazonClient d'Amazon_\n",
      "iter: 95 | Cliente AmazonCliente Amazon_\n",
      "iter: 96 | Cliente Kindle_\n",
      "iter: 97 | Cliente de AmazonCliente de Amazon_\n",
      "iter: 98 | Cliente de Kindle_\n",
      "iter: 99 | Cliente_\n",
      "iter: 100 | Colin_\n",
      "iter: 101 | Collin M._AEKMU6G2BJLYIWSE25BQSF7UEKGA\n",
      "iter: 102 | Corey Smith_AEPBOORKRFPG6LBDP756XA7O37XQ\n",
      "iter: 103 | Cory Maffeo_AFYHM2OBDTEUQTGGDCQGZCZX6Z4A\n",
      "iter: 104 | Courtney_\n",
      "iter: 105 | Craig_\n",
      "iter: 106 | Cristina_\n",
      "iter: 107 | Crystal_\n",
      "iter: 108 | Customer_\n",
      "iter: 109 | Cynthia_\n",
      "iter: 110 | D Henderson_\n",
      "iter: 111 | DD_\n",
      "iter: 112 | D_\n",
      "iter: 113 | Daisy_\n",
      "iter: 114 | Dan_\n",
      "iter: 115 | Dana_\n",
      "iter: 116 | DanielDaniel_\n",
      "iter: 117 | Daniel_\n",
      "iter: 118 | Daniela_\n",
      "iter: 119 | Danielle_\n",
      "iter: 120 | Danny_\n",
      "iter: 121 | Dave_\n",
      "iter: 122 | David_\n",
      "iter: 123 | Dawn_\n",
      "iter: 124 | Deb_\n",
      "iter: 125 | Debbie_\n",
      "iter: 126 | Dee_\n",
      "iter: 127 | Denise_\n",
      "iter: 128 | Dennis_\n",
      "iter: 129 | Derek_\n",
      "iter: 130 | Diana_\n",
      "iter: 131 | Diane_\n",
      "iter: 132 | Diego_\n",
      "iter: 133 | Donna_\n",
      "iter: 134 | Doug_\n",
      "iter: 135 | Dustin_AHWZKDPFP7DOCROU6EQ2KQYOLLCQ\n",
      "iter: 136 | Eduardo_\n",
      "iter: 137 | Elena_\n",
      "iter: 138 | Eli_\n",
      "iter: 139 | Elisa_\n",
      "iter: 140 | Elizabeth_\n",
      "iter: 141 | Elle_\n",
      "iter: 142 | Emily_\n",
      "iter: 143 | Emily_AHDLLMI4MNHIE7EID4CN25KMRRHQ\n",
      "iter: 144 | Emma_\n",
      "iter: 145 | Enrique_\n",
      "iter: 146 | Eric_\n",
      "iter: 147 | Erick_\n",
      "iter: 148 | Erik_\n",
      "iter: 149 | Erika_\n",
      "iter: 150 | Eva_\n",
      "iter: 151 | Eve_\n",
      "iter: 152 | Evelyn_\n",
      "iter: 153 | Fadi Shamaan_AH2UZ52SQ4HSIYYUEBYBY6R76JEA\n",
      "iter: 154 | Fernanda_\n",
      "iter: 155 | Fernando_\n",
      "iter: 156 | Francesca_\n",
      "iter: 157 | Francisco_\n",
      "iter: 158 | Frank_\n",
      "iter: 159 | Fred_\n",
      "iter: 160 | Froggydawn_AEPSDBF5KSMPPJONI5LRR3ZRIWKQ\n",
      "iter: 161 | G.R._\n",
      "iter: 162 | GB_\n",
      "iter: 163 | G_\n",
      "iter: 164 | Gabriel_\n",
      "iter: 165 | Gabriela_\n",
      "iter: 166 | Gary_\n",
      "iter: 167 | Gemma_\n",
      "iter: 168 | Gerardo_\n",
      "iter: 169 | Ginger271_AE4U2KV7YX3B6NHYGS2WXCO3MXXQ\n",
      "iter: 170 | Giuseppe_\n",
      "iter: 171 | Grace_\n",
      "iter: 172 | Greg_\n",
      "iter: 173 | Guillermo_\n",
      "iter: 174 | Gustavo_\n",
      "iter: 175 | Guy and Brandy_AG5HXY3U2RNHISWK4A7A5IJLDWDQ\n",
      "iter: 176 | H_\n",
      "iter: 177 | Hannah_\n",
      "iter: 178 | Harry _AELUZ4IIDBETBOOHUO6IOFX7EXTA\n",
      "iter: 179 | Heather_\n",
      "iter: 180 | Helen_\n",
      "iter: 181 | Henry_\n",
      "iter: 182 | Hugo_\n",
      "iter: 183 | Huy LeHuy Le_AGFN3252BBTYUJUUDQMAGYZNUT5A\n",
      "iter: 184 | Huy Le_AGFN3252BBTYUJUUDQMAGYZNUT5A\n",
      "iter: 185 | Héctor_\n",
      "iter: 186 | Ian_\n",
      "iter: 187 | Ivan_\n",
      "iter: 188 | JB_\n",
      "iter: 189 | JC_\n",
      "iter: 190 | JD_\n",
      "iter: 191 | JG_\n",
      "iter: 192 | JJ_\n",
      "iter: 193 | JL_\n",
      "iter: 194 | JM_\n",
      "iter: 195 | JP_\n",
      "iter: 196 | JR_\n",
      "iter: 197 | J_\n",
      "iter: 198 | Jack_\n",
      "iter: 199 | Jaime_\n",
      "iter: 200 | James_\n",
      "iter: 201 | Jamie_\n",
      "iter: 202 | Jan_\n",
      "iter: 203 | Jane_\n",
      "iter: 204 | Janet_\n",
      "iter: 205 | Jasmine_\n",
      "iter: 206 | Jason_\n",
      "iter: 207 | Javier_\n",
      "iter: 208 | Jay_\n",
      "iter: 209 | Jeff_\n",
      "iter: 210 | Jen_\n",
      "iter: 211 | Jenna_\n",
      "iter: 212 | Jennifer_\n",
      "iter: 213 | Jenny_\n",
      "iter: 214 | Jeremy_\n",
      "iter: 215 | Jess_\n",
      "iter: 216 | Jesse_\n",
      "iter: 217 | Jessica_\n",
      "iter: 218 | Jim_\n",
      "iter: 219 | Jo_\n",
      "iter: 220 | Jo_AHXFEMW5RPSWLG5ELU3CBSZHBTWQ\n",
      "iter: 221 | Joanne_\n",
      "iter: 222 | Joe_\n",
      "iter: 223 | Joel_\n",
      "iter: 224 | John_\n",
      "iter: 225 | John_AG6PIPVFXVM2UIU2LKEGND4SN6GQ\n",
      "iter: 226 | Jon_\n",
      "iter: 227 | Jonathan_\n",
      "iter: 228 | Jordan_\n",
      "iter: 229 | Jorge_\n",
      "iter: 230 | Jose_\n",
      "iter: 231 | Josh_\n",
      "iter: 232 | Joshua_\n",
      "iter: 233 | José_\n",
      "iter: 234 | Juan_\n",
      "iter: 235 | Judy_\n",
      "iter: 236 | Julia_\n",
      "iter: 237 | Julie_\n",
      "iter: 238 | JustJeri_AHHBLAHCHQSSHGMWMM23QNR7XAKA\n",
      "iter: 239 | Justin_\n",
      "iter: 240 | K_\n",
      "iter: 241 | Karen_\n",
      "iter: 242 | Karina_\n",
      "iter: 243 | Karla_\n",
      "iter: 244 | Kat_\n",
      "iter: 245 | Kate_\n",
      "iter: 246 | Katherine_\n",
      "iter: 247 | Kathy_\n",
      "iter: 248 | Katie_\n",
      "iter: 249 | Kelly_\n",
      "iter: 250 | Ken_\n",
      "iter: 251 | Kevin_\n",
      "iter: 252 | Kim_\n",
      "iter: 253 | Kimberley_\n",
      "iter: 254 | Kindle CustomerKindle Customer_\n",
      "iter: 255 | Kindle Customer_AF3S4W4MZOVO254JB7LB7QHOBAPA\n",
      "iter: 256 | Kindle Customer_AFWV7VHYZEGNA7TBCB62FUPVYOXQ\n",
      "iter: 257 | Kirsten_\n",
      "iter: 258 | Kristina_\n",
      "iter: 259 | Kyle_\n",
      "iter: 260 | L_\n",
      "iter: 261 | LadyRN_AHYU3PBS2HAOM27MF7CCY4NQMC7A\n",
      "iter: 262 | Larry_\n",
      "iter: 263 | Laura_\n",
      "iter: 264 | Lauren_\n",
      "iter: 265 | Laurie_\n",
      "iter: 266 | Lee_\n",
      "iter: 267 | Leo_\n",
      "iter: 268 | Leonardo_\n",
      "iter: 269 | Lesley_\n",
      "iter: 270 | Lily_\n",
      "iter: 271 | Linda_\n",
      "iter: 272 | Lindsay_\n",
      "iter: 273 | Lisa_\n",
      "iter: 274 | LiveWithTechLiveWithTech_AGZBRI6L4XCY3VS6LQGWV5I5HUAA\n",
      "iter: 275 | Liz_\n",
      "iter: 276 | Lorena_\n",
      "iter: 277 | Lori_\n",
      "iter: 278 | Lou_\n",
      "iter: 279 | Louise_\n",
      "iter: 280 | Lu_\n",
      "iter: 281 | Lucas_\n",
      "iter: 282 | Lucy_\n",
      "iter: 283 | Luis_\n",
      "iter: 284 | Luke_\n",
      "iter: 285 | Luna_\n",
      "iter: 286 | Lydia_\n",
      "iter: 287 | Lynn_\n",
      "iter: 288 | MB_\n",
      "iter: 289 | MC_\n",
      "iter: 290 | MJ_\n",
      "iter: 291 | MS_\n",
      "iter: 292 | M_\n",
      "iter: 293 | Manuel_\n",
      "iter: 294 | Marc_\n",
      "iter: 295 | Marco_\n",
      "iter: 296 | Marcos_\n",
      "iter: 297 | Marcy G._AE76BAELYPHA2Q6CIHRWEHZVVXMQ\n",
      "iter: 298 | Margarita_\n",
      "iter: 299 | Maria_\n",
      "iter: 300 | Mariana_\n",
      "iter: 301 | Marie_\n",
      "iter: 302 | Marilyn Smith_AEZ6NIHSI6VNXAYI4CFO5DRZDL5A\n",
      "iter: 303 | Marina_\n",
      "iter: 304 | Mario_\n",
      "iter: 305 | Marion L_\n",
      "iter: 306 | Mark_\n",
      "iter: 307 | Martha_\n",
      "iter: 308 | Martin_\n",
      "iter: 309 | Martina_\n",
      "iter: 310 | Mary_\n",
      "iter: 311 | Matt_\n",
      "iter: 312 | Matteo_\n",
      "iter: 313 | Matthew_\n",
      "iter: 314 | Mauricio_\n",
      "iter: 315 | Max_\n",
      "iter: 316 | Me_\n",
      "iter: 317 | Mel_\n",
      "iter: 318 | Melanie_\n",
      "iter: 319 | Melissa_\n",
      "iter: 320 | Michael_\n",
      "iter: 321 | Michelle_\n",
      "iter: 322 | Miguel_\n",
      "iter: 323 | Mike_\n",
      "iter: 324 | Miriam_\n",
      "iter: 325 | Mitch_\n",
      "iter: 326 | Monica_\n",
      "iter: 327 | Monika_\n",
      "iter: 328 | Monique_\n",
      "iter: 329 | Morgan_\n",
      "iter: 330 | Morgan_AFVLIAEZUT352MSUCI5JDEBREIMQ\n",
      "iter: 331 | Nadia_\n",
      "iter: 332 | Nancy Badillo_AF3B5PXRIGWOWRGPB7XIKWNEJNYA\n",
      "iter: 333 | Nancy_\n",
      "iter: 334 | Nat_\n",
      "iter: 335 | Natalia_\n",
      "iter: 336 | Natalie_\n",
      "iter: 337 | Nathalie_\n",
      "iter: 338 | Nathan_\n",
      "iter: 339 | Nelle Renn_AFVKHDD7S4DTJFHS7N5QAMNMMTCA\n",
      "iter: 340 | Nick_\n",
      "iter: 341 | Nicola_\n",
      "iter: 342 | Nicole_\n",
      "iter: 343 | Nina_\n",
      "iter: 344 | Nora_\n",
      "iter: 345 | Oscar_\n",
      "iter: 346 | P. Blevins_AH5OZRDARE5O55VBCRBHWGYCO5WQ\n",
      "iter: 347 | P. Sleijpen_AGAYPXNHKSEBFWQ7CLLPQFP2QQBQ\n",
      "iter: 348 | Pablo_\n",
      "iter: 349 | Pam_\n",
      "iter: 350 | Pamela_\n",
      "iter: 351 | Paolo_\n",
      "iter: 352 | Pat_\n",
      "iter: 353 | Patricia_\n",
      "iter: 354 | Patrick_\n",
      "iter: 355 | Paul_\n",
      "iter: 356 | Paula_\n",
      "iter: 357 | Paulina_\n",
      "iter: 358 | Pedro_\n",
      "iter: 359 | Penny Lane_AGH62UUHMMOSEJPZP3DBQN67WW5A\n",
      "iter: 360 | Peter_\n",
      "iter: 361 | Phil_\n",
      "iter: 362 | Pickle_\n",
      "iter: 363 | Pierre_\n",
      "iter: 364 | Placeholder_\n",
      "iter: 365 | PrimingFXPrimingFX_AGVPOGRS47VFWNPPETZVV2EZLK6Q\n",
      "iter: 366 | Queenvik_AFGNSU5FBITFSXMJV4KATMYURMGA\n",
      "iter: 367 | RJ_\n",
      "iter: 368 | R_\n",
      "iter: 369 | Rachel_\n",
      "iter: 370 | Rafael_\n",
      "iter: 371 | Randy_\n",
      "iter: 372 | Raul_\n",
      "iter: 373 | Ray_\n",
      "iter: 374 | Ray_AGXTFB5G7RAFCWOCIATX2KBXLVXQ\n",
      "iter: 375 | Real Deal_AE7Z57LXPIPMXRIFXY6673V6HTDA\n",
      "iter: 376 | Rebeca_\n",
      "iter: 377 | Rebecca_\n",
      "iter: 378 | RedXepher82RedXepher82_AF6RFVIK2MSSR3PQTKQKAVK4HNRQ\n",
      "iter: 379 | RedXepher82_AF6RFVIK2MSSR3PQTKQKAVK4HNRQ\n",
      "iter: 380 | Ricardo_\n",
      "iter: 381 | Richard G_AGXTDTEP5ODOQCRDSOTW3UMFEDBA\n",
      "iter: 382 | Richard_\n",
      "iter: 383 | Rick_\n",
      "iter: 384 | Rita_\n",
      "iter: 385 | Rob_\n",
      "iter: 386 | Robert_\n",
      "iter: 387 | Roberto_\n",
      "iter: 388 | Robin_\n",
      "iter: 389 | Rodrigo_\n",
      "iter: 390 | Ron_\n",
      "iter: 391 | Rose_\n",
      "iter: 392 | Roxanne_\n",
      "iter: 393 | Ruth_\n",
      "iter: 394 | Ryan_\n",
      "iter: 395 | S._\n",
      "iter: 396 | SD_\n",
      "iter: 397 | SG_\n",
      "iter: 398 | SM_\n",
      "iter: 399 | SP_\n",
      "iter: 400 | S_\n",
      "iter: 401 | Sabrina_\n",
      "iter: 402 | Sally_\n",
      "iter: 403 | SamSam_\n",
      "iter: 404 | Sam_\n",
      "iter: 405 | Samantha_\n",
      "iter: 406 | Sandra_\n",
      "iter: 407 | Sandy_\n",
      "iter: 408 | Sara_\n",
      "iter: 409 | Sarah _\n",
      "iter: 410 | Sarah_\n",
      "iter: 411 | Scott_\n",
      "iter: 412 | Sean_\n",
      "iter: 413 | Sebastian_\n",
      "iter: 414 | Secret Angel _AHSUZYOVB3BHGXLADUXJ7VRSSOXA\n",
      "iter: 415 | Sergej M._AF337A4LOE6XZ4R2ZEIN3HCQQ6YQ\n",
      "iter: 416 | Sergio_\n",
      "iter: 417 | Shannon_\n",
      "iter: 418 | Sharon_\n",
      "iter: 419 | Shawn_\n",
      "iter: 420 | Sheila_\n",
      "iter: 421 | Shelly_\n",
      "iter: 422 | Sherri3d_AEIAJMYN3AFXKBVMD3GYN5RHZGEQ\n",
      "iter: 423 | Silvia_\n",
      "iter: 424 | Simon_\n",
      "iter: 425 | Simone_\n",
      "iter: 426 | Somer_AESMYA7MCLFHRZ3HYKG2A3BVVSIQ\n",
      "iter: 427 | Sonia_\n",
      "iter: 428 | Sophie_\n",
      "iter: 429 | Stacey_\n",
      "iter: 430 | Steph_\n",
      "iter: 431 | Stephanie_\n",
      "iter: 432 | Steve_\n",
      "iter: 433 | Steven_\n",
      "iter: 434 | Steven_AHPRRIDI7LA42GJZ7OKWELQPNOIQ\n",
      "iter: 435 | Sue_\n",
      "iter: 436 | Sunrise CircleSunrise Circle_AETGSOE6YE5FT4H4FQHYEMUEJ4NA\n",
      "iter: 437 | Susan_\n",
      "iter: 438 | Suzanne_\n",
      "iter: 439 | Sylvie_\n",
      "iter: 440 | TM ConwayTM Conway_AHE6A2KMCMQSOHCMNE7JQHSAHTRQ\n",
      "iter: 441 | T_\n",
      "iter: 442 | Tammy_\n",
      "iter: 443 | Tanya_\n",
      "iter: 444 | Tara_\n",
      "iter: 445 | Taylor_\n",
      "iter: 446 | Teresa_\n",
      "iter: 447 | Terry_\n",
      "iter: 448 | Thomas_\n",
      "iter: 449 | Tiffany_\n",
      "iter: 450 | Tim_\n",
      "iter: 451 | Tina_\n",
      "iter: 452 | Tom_\n",
      "iter: 453 | Tony_\n",
      "iter: 454 | Tracey_\n",
      "iter: 455 | TracyJane_AH4XZXKYMBCASW7ESD2KPE2G7TQA\n",
      "iter: 456 | Tracy_\n",
      "iter: 457 | Tyler_\n",
      "iter: 458 | Unspoken Yum_AH2JCQEWME2H6ZGCDIRIQWUKHSRQ\n",
      "iter: 459 | V_\n",
      "iter: 460 | Val_\n",
      "iter: 461 | Vanessa_\n",
      "iter: 462 | Victor_\n",
      "iter: 463 | Victoria_\n",
      "iter: 464 | Vr_\n",
      "iter: 465 | Wehash Technology_AGNFPNLEVHI6AF2OA3TFEV52YZ5Q\n",
      "iter: 466 | Wendy_\n",
      "iter: 467 | William_\n",
      "iter: 468 | XennialLifeXennialLife_AGXDPEOXPMPIHIWPVXTBYFBYVP3A\n",
      "iter: 469 | Yalal Besereni_AF4PA2JDHXJ6SYSKLOTP7LKLY7IA\n",
      "iter: 470 | Yolanda_\n",
      "iter: 471 | ana_\n",
      "iter: 472 | barbara gerling_AHQBKGDOJJZBXK3VI73NJ775MINA\n",
      "iter: 473 | c'est la vie🎉😘c'est la vie🎉😘_AFIOHAAJI7BOBSJGV2YIYRCZ3CCA\n",
      "iter: 474 | carol_AFK6NGLVCLZJI7637XZ7RXI2N2LQ\n",
      "iter: 475 | chris_\n",
      "iter: 476 | dac_AHK2DUBBBFRGDSNKJG6CQA7AT3OA\n",
      "iter: 477 | david_\n",
      "iter: 478 | live love laugh_AGEJVATBEAWO46BMRZTXDTIANJFQ\n",
      "iter: 479 | mike_\n",
      "iter: 480 | susan shelton_\n",
      "iter: 481 | ¤♤♡◇♧□○°_AGUTZC4GHLTGYHA3KBEDRF6MHB6A\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "rows = []\n",
    "iter = 0\n",
    "columns = pd.unique(all_reviews_df['ASIN']).tolist()\n",
    "columns.append(\"reviewerID\")\n",
    "\n",
    "for index, data in user_ratings_grouped_df:\n",
    "    print(f\"iter: {iter} | {index}\")\n",
    "    data = data.to_dict()\n",
    "    row = {}\n",
    "    row[\"reviewerID\"] = index\n",
    "    for i in data[\"ASIN\"]:\n",
    "        asin = data[\"ASIN\"][i]\n",
    "        rating = data[\"reviewRating\"][i]\n",
    "        row[asin] = rating\n",
    "    rows.append(row)\n",
    "    iter += 1\n",
    "fname = f\"{save_to_dir}/utility_topn.csv\"\n",
    "with open(fname, 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=columns)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1d1b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{save_to_dir}/utility_topn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89d4e8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B087CDBKCH</th>\n",
       "      <th>B0BZXNSW5K</th>\n",
       "      <th>B0BX59CFN1</th>\n",
       "      <th>1685795714</th>\n",
       "      <th>1542034299</th>\n",
       "      <th>B0BHFBQ76G</th>\n",
       "      <th>B0C4BHDZGM</th>\n",
       "      <th>0735221103</th>\n",
       "      <th>B008LQXR9Q</th>\n",
       "      <th>B0BXQS3JKP</th>\n",
       "      <th>...</th>\n",
       "      <th>B0BCDR9M33</th>\n",
       "      <th>B09TWVPXS5</th>\n",
       "      <th>B07MMD4DDJ</th>\n",
       "      <th>B07Q11QQCM</th>\n",
       "      <th>B086MHTK5C</th>\n",
       "      <th>B086MHSH2Z</th>\n",
       "      <th>B086ML4XSB</th>\n",
       "      <th>B08V1T4JC1</th>\n",
       "      <th>B0759FGJ3Q</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>***Toy Collector***_AG5NFKDKQNEYV76GKH7BMXNTHKSQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A._</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AJ_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aaron_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>david_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live love laugh_AGEJVATBEAWO46BMRZTXDTIANJFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mike_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>susan shelton_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>¤♤♡◇♧□○°_AGUTZC4GHLTGYHA3KBEDRF6MHB6A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows × 435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     B087CDBKCH  B0BZXNSW5K  B0BX59CFN1  1685795714  1542034299  B0BHFBQ76G  \\\n",
       "0           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "477         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "478         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "479         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "480         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "481         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     B0C4BHDZGM  0735221103  B008LQXR9Q  B0BXQS3JKP  ...  B0BCDR9M33  \\\n",
       "0           NaN         NaN         NaN         NaN  ...         NaN   \n",
       "1           NaN         NaN         NaN         NaN  ...         NaN   \n",
       "2           NaN         NaN         NaN         NaN  ...         NaN   \n",
       "3           NaN         NaN         NaN         NaN  ...         NaN   \n",
       "4           NaN         NaN         NaN         NaN  ...         NaN   \n",
       "..          ...         ...         ...         ...  ...         ...   \n",
       "477         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "478         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "479         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "480         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "481         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "\n",
       "     B09TWVPXS5  B07MMD4DDJ  B07Q11QQCM  B086MHTK5C  B086MHSH2Z  B086ML4XSB  \\\n",
       "0           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "477         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "478         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "479         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "480         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "481         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     B08V1T4JC1  B0759FGJ3Q                                        reviewerID  \n",
       "0           NaN         NaN  ***Toy Collector***_AG5NFKDKQNEYV76GKH7BMXNTHKSQ  \n",
       "1           NaN         NaN                                               A._  \n",
       "2           NaN         NaN                                               AJ_  \n",
       "3           NaN         NaN                                                A_  \n",
       "4           NaN         NaN                                            Aaron_  \n",
       "..          ...         ...                                               ...  \n",
       "477         NaN         NaN                                            david_  \n",
       "478         NaN         NaN      live love laugh_AGEJVATBEAWO46BMRZTXDTIANJFQ  \n",
       "479         NaN         NaN                                             mike_  \n",
       "480         NaN         NaN                                    susan shelton_  \n",
       "481         NaN         NaN             ¤♤♡◇♧□○°_AGUTZC4GHLTGYHA3KBEDRF6MHB6A  \n",
       "\n",
       "[482 rows x 435 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_non_null_vals_cols = [col for col in df.columns if df[col].any() & ~df[col].eq(np.nan).all()]\n",
    "df.loc[:, has_non_null_vals_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "122ed225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 33667)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e03656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
