{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup Scripts\n",
    "1. Use this to clean up files before pushing to Github to make them windows ingestible\n",
    "2. Use this to manually create the item type csv files in case the crawling process gets interrupted for some reason.\n",
    "3. Count the number of items so far in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30888"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of products so far\n",
    "walk_dir = f'extracts/amazon'\n",
    "cnt = 0\n",
    "for root, subdirs, files in os.walk(walk_dir):\n",
    "    for file in files:\n",
    "        if '.json' in file and 'sspa' not in file:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually create csv file for an item\n",
    "# use this in case the crawler process gets interrupted\n",
    "columns = [\n",
    "    \"url\", \"name\", \"asin\",\n",
    "    \"image\", \"price\", \"isPrime\",\n",
    "    \"offer\", \"customerReview\", \"customerReviewCount\"\n",
    "]\n",
    "\n",
    "item_name = 'pc chassis'\n",
    "walk_dir = f'extracts/amazon/{item_name}'\n",
    "product_data = []\n",
    "for root, subdirs, files in os.walk(walk_dir):\n",
    "    for file in files:\n",
    "        row = {}\n",
    "        if 'sspa.json' not in file and '.csv' not in file and '_.json' not in file and '.txt' not in file:\n",
    "            f = open(os.path.join(root,file))\n",
    "            data = json.load(f)\n",
    "            f.close()\n",
    "\n",
    "            row['url'] = data['url']\n",
    "            try:\n",
    "                row['asin'] = data['body']['productInformation'][2]['value']\n",
    "            except:\n",
    "                row['asin'] = row['url'].split('/')[-1]\n",
    "            try:\n",
    "                row['name'] = data['body']['name']\n",
    "            except:\n",
    "                row['name'] = row['asin']\n",
    "            try:\n",
    "                row['image'] = data['body']['mainImage']\n",
    "            except:\n",
    "                row['image'] = None\n",
    "            try:\n",
    "                row['price'] = data['body']['price']\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                row['offer'] = data['offer']\n",
    "            except:\n",
    "                row['offer'] = None\n",
    "            try:\n",
    "                row['customerReview'] = data['body']['customerReview']\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                row['customerReviewCount'] = data['body']['customerReviewCount']\n",
    "            except:\n",
    "                continue\n",
    "            product_data.append(row)\n",
    "df = pd.DataFrame(product_data, columns=columns)\n",
    "df.to_csv(f\"extracts/amazon/{item_name}/amazon_{item_name}_manual.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up filenames and make them ingestible on Windows\n",
    "walk_dir = 'extracts/amazon'\n",
    "\n",
    "for root, subdirs, files in os.walk(walk_dir):\n",
    "    for file in files:\n",
    "        if '.json' in file:\n",
    "            fname = file.split('.')[0]\n",
    "            fname = fname[:30] + '.json' # just take first 30 characters\n",
    "            os.rename(\n",
    "                os.path.join(root,file),\n",
    "                os.path.join(root, fname)\n",
    "            )\n",
    "        if '.txt' in file:\n",
    "            fname = file.split('.')[0]\n",
    "            fname = fname.replace(':', '').replace('-', '').replace(' ', '_') + '.txt'\n",
    "            os.rename(\n",
    "                os.path.join(root,file),\n",
    "                os.path.join(root, fname)\n",
    "            )\n",
    "        if '.csv' in file:\n",
    "            fname = file.split('.')[0]\n",
    "            fname = fname.replace(':', '').replace('-', '').replace(' ', '_') + '.csv'\n",
    "            os.rename(\n",
    "                os.path.join(root,file),\n",
    "                os.path.join(root, fname)\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
